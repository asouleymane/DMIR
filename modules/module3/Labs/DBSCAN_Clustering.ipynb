{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 DBSCAN Clustering\n",
    "\n",
    "Cluster Analysis is an important problem in data analysis. It is used to cluster data to do market research, pattern recognition, image processing, classifying documents for information discovery, credit card fraud detection, grouping genes with similar patterns and so many other applications.\n",
    "\n",
    "There are different types of Clustering algorithms as we have K-Means and Hierarchical in other lab notebooks. K-Means determines k centroids in the data and clusters points by assigning points to the nearest centroid.\n",
    "\n",
    "While K-Means is easy to understand and implement, it cannot detect any outliers in data. All points are assigned to a cluster even if they do not belong in any. But in reality this causes a problem as anomalous points will be assigned to the same cluster as \"normal\" valid data points. The anomalous points pull the cluster centroid towards them, making it harder to classify them as anomalous points.\n",
    "\n",
    "Another type of clustering methods are density-based. Compared to centroid-based clustering like K-Means, density-based clustering works by identifying \"dense\" clusters of points, allowing it to learn clusters of arbitrary shape and identify outliers in the data. This lab notebook discusses popular DBSCAN algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\epsilon$ neighborhood and neighborhood density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ɛ-neighborhoods:** Given a data point, identify the data points around in the space arund it. For some real-valued ɛ > 0 and some point **p**, the $\\epsilon$-neighborhood of p is defined as the set of points that are at most distance $\\epsilon$ away from **p**.\n",
    "\n",
    "The shape in which all points are equidistant from the center will be a circle. In a 2D space, the $\\epsilon$-neighborhood of a point **p** is the set of points contained in the circle of radius $\\epsilon$, centered at **p**. In 3D space, the $\\epsilon$-neighborhood is a sphere of radius $\\epsilon$, centered at **p**, and in higher dimensional space, the $\\epsilon$-neighborhood is just the N-sphere of radius $\\epsilon$, centered at **p**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a dummy dataset generated using numpy.random numbers. There are 50 data points. Lets choose the center as (0,0) which wil be the point p in the discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate 50 random random numbers in a normal distribution\n",
    "x=np.random.randn(50)\n",
    "\n",
    "# generate 50 random random numbers in a normal distribution and add x to it, so that x and y are correlated. \n",
    "# Because every element of y contains x which makes them co related\n",
    "y=x+np.random.randn(50)\n",
    "\n",
    "print(x[1:5])\n",
    "print(y[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Draw scatter plot for x and y\n",
    "plt.scatter(x,y)\n",
    "\n",
    "# Highlight the chosen point p in red color\n",
    "plt.scatter(0, 0, c='r')  # plot interesting points in red again\n",
    "\n",
    "# enable grid on the plot\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s consider the neighborhood of p with radius 0.5 (ɛ = 0.5), the set of points that are distance 0.5 away from p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a circle around the point (0,0) with radius 0.4. color='g' lets the circle be of color green and fill=True \n",
    "# fills the circle. alpha=0.1 tells how thick the circle should be filled. It ranges from  to 1. 0 being no fill to 1 being \n",
    "# completely filled. A value of 0.1 will make the circle look transparent. \n",
    "circle = plt.Circle((0, 0), 0.4, color='g', fill=True, alpha=0.1)\n",
    "\n",
    "# generate a figure with size as mentioned\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# draw scatter plot using x and y\n",
    "plt.scatter(x,y,  label = \"Data\")\n",
    "\n",
    "# Highlight the point p again. \n",
    "plt.scatter(0, 0, c='r', label = \"point p\")  # plot interesting points in red again\n",
    "plt.grid()\n",
    "\n",
    "# Add legend to the plot. loc=2 will tell python to put legend at top left corner. You can try different loc values like 1,2,3,4\n",
    "plt.legend(loc = 2)\n",
    "plt.title(\"Neighbourhood with radius 0.4\")\n",
    "\n",
    "# add the circle created above to the plot. \n",
    "ax.add_artist(circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The green oval represents the neighborhood of point **p**, and there are 3 data points in this neighborhood. Since there are a total of 50 scattered data points and 3 are in the neighborhood, this means that under one-tenth of the data points are contained within the neighborhood of p with radius 0.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now change the radius to 0.2 ($\\epsilon$ = 0.2) and consider the resulting smaller neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "circle = plt.Circle((0, 0), 0.2, color='g', fill=True, alpha=0.1)\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plt.scatter(x,y,  label = \"Data\")\n",
    "plt.scatter(0, 0, c='r', label = \"point p\")  # plot interesting points in red again\n",
    "plt.grid()\n",
    "plt.legend(loc = 2)\n",
    "plt.title(\"Neighbourhood with radius 0.2\")\n",
    "ax.add_artist(circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neighborhood has shrunk. There is only 1 data point in it now. By decreasing $\\epsilon$ from 0.4 to 0.2 (a 50% reduction), the number of points in the neighborhood decreased from 3 to 1 (a 67% reduction).\n",
    "\n",
    "**Density of a neighborhood: **  If you go back to your science text book in high school, density is given as\n",
    "\n",
    "$$density = \\frac{mass}{volume}$$. \n",
    "\n",
    "Use this idea of mass divided by volume to define density at point p. Consider a point p and its neighborhood of radius $\\epsilon$, the mass of the neighborhood can be defined as the number of data points contained within the neighborhood, and the volume of the neighborhood is volume of the resulting shape of the neighborhood. Here the neighborhood is a circle, so the volume of the neighborhood is the area of the resulting circle.\n",
    "\n",
    "For example, consider the neighborhood of point p = (0,0) of radius 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "circle = plt.Circle((0, 0), 0.4, color='g', fill=True, alpha=0.1)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "plt.scatter(x,y,  label = \"Data\")\n",
    "plt.scatter(0, 0, c='r', label = \"point p\")  # plot interesting points in red again\n",
    "plt.grid()\n",
    "plt.legend(loc = 2)\n",
    "plt.title(\"Neighbourhood with radius 0.4\")\n",
    "ax.add_artist(circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mass is the number of data points in the neighborhood, so mass = 3. The volume is the area of the circle, so volume = $\\pi$ * 0.52 = $\\pi$/4. Therefore, the local density approximation at **p** = (0,0) is calculated as density = mass/volume = 3/($\\pi$/4) = 12/$\\pi$ ~= 3.82.\n",
    "\n",
    "This single density value is meaningless by itself, but when local density approximation for all points in the dataset is calculated, then points can be clustered by saying that points that are nearby (contained in the same neighborhood) and have similar local density approximations belong in the same cluster. If the value of $\\epsilon$ is decreased, smaller neighborhoods (less volume) are formed which will contain fewer data points. DBSCAN tries to identify highly dense neighborhoods where most of the data points are contained in these neighborhoods, but the volume of each of these neighborhoods is relatively small.\n",
    "\n",
    "This is the general intuition behind a density-based clustering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN, unlike K-Means does not require the number of clusters as a parameter. It will infer the number of clusters based on the data, and it can discover clusters of arbitrary shape which K-Means cannot. DBSCAN algorithm has two parameters:\n",
    "\n",
    "- $\\epsilon$: The radius of neighborhood around a data point p.\n",
    "- minPts: The minimum number of data points that should be in a neighborhood to define a cluster.\n",
    "\n",
    "Using abve two parameters, DBSCAN categories the data points into three categories:\n",
    "\n",
    "- **Core Points:** A data point p is a core point if $\\epsilon$-neighborhood of p contains at least minPts\n",
    "\n",
    "- **Border Points:** A data point q in the dataset is a border point if $\\epsilon$-neighborhood of q contains less than minPts data points, but q is reachable from some core point p.\n",
    "\n",
    "- **Outlier:** A data point o is an outlier if it is neither a core point nor a border point. Essentially, this is the “other” class.\n",
    "\n",
    "Let’s discuss these definitions little in depth. \n",
    "\n",
    "**Core Points**\n",
    "\n",
    "Core Points are the foundations of clusters. The core points are based on the density approximation. The same $\\epsilon$ is used to compute the neighborhood for each point, so the volume of all the neighborhoods is same. However, the number of other points in each neighborhood is what differs. \n",
    "\n",
    "The number of data points in the neighborhood can be treated as its mass. The volume of each neighborhood is constant, and the mass of neighborhood is variable, so by putting a threshold on the minimum amount of mass needed to be core point, we are essentially setting a minimum density threshold. Therefore, core points are data points that satisfy a minimum density requirement. The clusters are built around the core points, so by adjusting the minPts parameter the density of clusters can be fin etuned.\n",
    "\n",
    "**Border Points: **\n",
    "\n",
    "Border Points are the points in the clusters that are not core points. The term density-reachable is used in the definition above. Lets create a neighborhood with epsilon = 0.65 for our point p(0,0). Consider the point r (the black dot) that is outside of the point p's neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "circle1 = plt.Circle((0, 0), 0.65, color='g', fill=True, alpha=0.1)\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plt.scatter(x,y,  label = \"Data\")\n",
    "plt.scatter(0, 0, c='r', label = \"point p\")  # plot interesting points in red again\n",
    "plt.scatter(-0.93343688,-0.78195153, c='black', label = \"point r outside p's neighbourhood\")  # plot interesting points in red again\n",
    "plt.grid()\n",
    "plt.legend(loc = 2)\n",
    "plt.title(\"Neighbourhood with radius 0.2\")\n",
    "ax.add_artist(circle1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the points inside the point p's neighborhood are directly reachable from p. Let’s explore the neighborhood of another point q, a point directly reachable from p. purple circle represents q's neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "circle1 = plt.Circle((0, 0), 0.65, color='g', fill=True, alpha=0.1)\n",
    "# patches.Circle((0.82, 0.5), 0.1,alpha=0.1)\n",
    "circle2 = plt.Circle((-0.54701334,-0.27689633), 0.65, color='purple', fill=True, alpha=0.1, label = \"Neighborhood\")\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plt.scatter(x,y,  label = \"Data\")\n",
    "plt.scatter(0, 0, c='r', label = \"point p\")  # plot interesting points in red again\n",
    "plt.scatter(-0.54701334,-0.27689633, c='purple', label = \"point q\")  # plot interesting points in red again\n",
    "plt.scatter(-0.93343688,-0.78195153, c='black', label = \"point r in q's neighbourhood\")  # plot interesting points in red again\n",
    "plt.grid()\n",
    "plt.legend(loc = 2)\n",
    "plt.title(\"Neighbourhood with radius 0.2\")\n",
    "ax.add_artist(circle1)\n",
    "ax.add_artist(circle2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target point r is not the starting point p's neighborhood, it is contained in the point q's neighborhood. Basically this is the idea behind density-reachable. If we can get to the point r by jumping from neighborhood to neighborhood, starting at a point p, then the point r is density-reachable from the point p.\n",
    "\n",
    "It is important to note that this idea of density-reachable is dependent on the value of $\\epsilon$. By picking larger values of $\\epsilon$, more points become density-reachable, and by choosing smaller values of $\\epsilon$, less points become density-reachable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers: **\n",
    "\n",
    "Finally, the points which are neither core nor desnity-reachable from a core point that are grouped into \"other\" class. Outliers are not assigned to any cluster and, depending on the context, may be considered anomalous points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for DBSCAN algorithm:\n",
    "\n",
    "- Pick a point at random that has not been assigned to a cluster or been designated as an outlier. Compute its neighborhood to determine if it’s a core point. If yes, start a cluster around this point. If no, label the point as an outlier.\n",
    "\n",
    "\n",
    "- Once core point and a cluster is identified , expand the cluster by adding all directly-reachable points to the cluster. Perform “neighborhood jumps” to find all density-reachable points and add them to the cluster. If an an outlier is added, change that point’s status from outlier to border point.\n",
    "\n",
    "\n",
    "- Repeat above steps until all points are either assigned to a cluster or designated as an outlier.\n",
    "\n",
    "Python's Scikit-Learn library has the iplementation of DBSCAN algorithm. So just use the functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN Implementtaion\n",
    "----\n",
    "Lets move on to applying DBSCAN algorithm on a dataset to compare the clusters it forms with KMeans. Apply the algorithm on wholesale dataset from UCI machine learning repository. The dataset consists of annual customer data for a wholesale distributor. It has data about 440 customers and has 8 attributes for each of these customers. Use Pandas library to load the .csv file into a DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wholesale_data = pd.read_csv(\"../../../datasets/wholesale/Wholesale_customers_data.csv\")\n",
    "wholesale_data.drop([\"Channel\", \"Region\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two fields identify the customer. They are deleted above. Examine the first few rows of the dataset using head()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wholesale_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustrating the working of algorithm, data only with below two attributes are used.\n",
    "\n",
    "- **Groceries:** The customer’s annual spending on grocery products.\n",
    "\n",
    "- **Milk:** The customer’s annual spending on milk products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wholesale_data = wholesale_data[[\"Grocery\", \"Milk\"]]\n",
    "wholesale_data = wholesale_data.as_matrix().astype(\"float32\", copy = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The StandardScalar() function below will normalize each attribute by scaling it to 0 mean and unit variance. All attribute values represent spendings of customer by some monetary unit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stscaler = StandardScaler().fit(wholesale_data)\n",
    "data = stscaler.transform(wholesale_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below plot is for the normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.xlabel(\"Groceries\")\n",
    "plt.ylabel(\"Milk\")\n",
    "plt.title(\"Wholesale Data - Groceries and Milk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot it is evident that there is a positive correlation between grocery purchases and milk product purchases. There is a cluster centered about the mean milk purchase (milk = 0) and the mean groceries purchase (groceries = 0). Also there are few outliers pertaining to customers who buy more wgroceries or milk products compared to other customers.\n",
    "\n",
    "With DBSCAN, lets try to identify this main cluster of customers and flag those customers with more unusual annual purchasing habits as outliers.\n",
    "\n",
    "Below piece of code will construct a DBSCAN object that requires a minimum of 15 data points in a neighborhood of radius 0.5 to be considered a core point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbscan_res = DBSCAN(eps = .5, min_samples = 15).fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are extracting the cluster labels and outliers to plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = dbscan_res.labels_\n",
    "core_samples = np.zeros_like(labels, dtype = bool)\n",
    "core_samples[dbscan_res.core_sample_indices_] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_labels = np.unique(labels)\n",
    "colors = plt.cm.Spectral(np.linspace(0,1, len(unique_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (label, color) in zip(unique_labels, colors):\n",
    "    class_member_mask = (labels == label)\n",
    "    xy = data[class_member_mask & core_samples]\n",
    "    plt.plot(xy[:,0],xy[:,1], 'o', markerfacecolor = color, markersize = 10)\n",
    "    \n",
    "    xy2 = data[class_member_mask & ~core_samples]\n",
    "    plt.plot(xy2[:,0],xy2[:,1], 'o', markerfacecolor = color, markersize = 5)\n",
    "    \n",
    "plt.title(\"DBSCAN on Wholsesale data\")\n",
    "plt.xlabel(\"Grocery (scaled)\")\n",
    "plt.ylabel(\"Milk (scaled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above plot, we can say DBSCAN algorithm was able to identify one cluster of customers who are about the mean grocery and mean milk product purchases. In addition, it was able to flag customers whose annual purchasing behavior deviated too heavily from other customers.\n",
    "\n",
    "Because the outliers corresponded to customers with more extreme purchasing behavior, the wholesale distributor could specifically target these customers with exclusive discounts to encourage larger purchases.\n",
    "\n",
    "As a baseline, let’s run K-Means with two clusters. The blue dot represents the centroid for the red cluster, and the big gold dot represents the centroid for the blue cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 2).fit(data)\n",
    "labels_kmeans = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(data[:,0], data[:,1], c = labels_kmeans)\n",
    "plt.scatter(centroids[:,0], centroids[:,1], c = [\"gold\",\"blue\"], s = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the blue clusters appears to capture most of the outliers, the cluster basically captures customers who purchase relatively more goods. If the blue cluster is designated as the \"anomalous\" cluster, We are basically flagging any customer who purchases a lot of milk or groceries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
