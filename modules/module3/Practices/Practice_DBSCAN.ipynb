{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 DBSCAN Practice\n",
    "\n",
    "\n",
    "The activities in this notebook are similar to what you seen in the lab notebook. Most of the activities are either partially complete for you to finish them while some of them might require you to work out the whole code for the activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate sample data\n",
    "\n",
    "**make_blobs(): ** Generates isotropic Gaussian blobs for clustering. \n",
    "\n",
    "**centers:**  parameter is used to specify number of centers to generate. It takes input in the form of either \"int or array of shape [n_centers, n_features]\". \n",
    "\n",
    "**cluster_std :** The standard deviation of the clusters.\n",
    "\n",
    "**random_state :** int, RandomState instance or None, optional (default=None)\n",
    "If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# centers of clusters\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "\n",
    "# Create blobs with 3 different centers\n",
    "Data, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4, random_state=0)\n",
    "print(Data[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the function make_blobs() generated samples 75. samples of data. Data has the x,y coordicates of blobs created and labels_true has the labels to which center the blob belongs to. Below function \"StandardScaler().fit_transform(X)\" standardizes Data by converting them to zero mean and scaling to unit variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 1: ** Use the StandardScalar() function to normalize Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer for activity 1 goes here...\n",
    "\n",
    "Data = <what goes in here>\n",
    "Data[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 2: ** Run the DBSCAN algorithm on Data to construct a DBSCAN object that requires a minimum of 10 data points in a neighborhood of radius 0.3 to be considered a core point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer for activity 2 goes here...\n",
    "\n",
    "db = DBSCAN(<what goes in here>).fit(<what goes in here>)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(db.labels_[1:20])\n",
    "labels_true[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the labels returned by dbscan, they are almost same as the labels returned by make_blobs(). There are some -1's apart from {0,1,2}. The -1's represent samples/blobs which couldn't be included in any of the clusters. You can call them outliers in this context but they really are not outliers. They just didnt fit the criteria the algorithm is using to cluster the points. \n",
    "\n",
    "Lets generate a vector equal to size of number of labels and filled with boolean values. np.zeros_like() will create a zeros vector but we specified data type as boolean. Since zeros represent False, the vector is populated with False values. \n",
    "\n",
    "**Referenec: ** [numpy.zeros_like()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below displayed is the list of samples indices which were formed into clusteres. Notice that index 5 is missing in the first 10 samples indicating sample 5 was not fitted into any cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.core_sample_indices_[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 3: ** Assign \"True\" to the indexes in core_samples_mask list for the samples where dbscan was able to cluster the points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer for activity 3 goes here...\n",
    "\n",
    "core_samples_mask[<what goes in here>] = True\n",
    "core_samples_mask[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So DBScan was able to label the samples with one of the 4 values {-1, 0, 1, 2}. The values {0, 1, 2 } are labels for valid clusters formed. Below piece of code is reducing the number of clusters by 1 if there are any -1 labels in the list. That will give the actual count of number of clusters formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference: ** [metrics.homogeneity_score()](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_score.html)\n",
    "\n",
    "Homogeneity metric of a cluster labeling given a ground truth. This function will check accuracy of the predictions. The first argument is the true labels which are stored in the list labels_true. labels_true was returned by make_blobs() function while producing the samples. Its the ground truth. The second parameter is the predictions which are stored in the list labels. The function will cross check the labels in both lists to give the accuracy of predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference: ** [sklearn.metrics.completeness_score(labels_true, labels_pred)](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.completeness_score.html)\n",
    "\n",
    "A clustering result satisfies completeness if all the data points that are members of a given class are elements of the same cluster. Both homogeneity and completeness scores have positive values between 0.0 and 1.0, larger values being desirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(Data, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From wiki, The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette values range from -1 to 1, where a high value (i'e closer to 1) indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high value, then the clustering configuration is appropriate. If many points have a low or negative value, then the clustering configuration may have too many or too few clusters.\n",
    "\n",
    "The silhouette can be calculated with any distance metric, such as the Euclidean distance or the Manhattan distance.\n",
    "\n",
    "**Reference: ** [Python documentation for silhoutte](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, first we are assigning unique values {-1, 0, 1, 2} to variable unique_labels. Then using [matplotlib colormap](http://matplotlib.org/api/cm_api.html) module we are generating different colors scheme for each unique label. Spectral is a kind of color map. It is used where the data has a critical middle value. The map consists of two colours with changes in lightness and saturation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_labels = set(labels)\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference: **\n",
    "- [Color maps in Matplotlib](http://www.futurile.net/2016/03/31/colormaps-in-matplotlib/)\n",
    "- [Color maps reference](http://matplotlib.org/examples/color/colormaps_reference.html)\n",
    "- [Setting the color of a matplotlib plot](http://chrisalbon.com/python/set_the_color_of_a_matplotlib.html)\n",
    "\n",
    "------\n",
    "\n",
    "**zip():** This function takes two equal-length collections, and merges them together in pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 4: ** Use this on unique_labels and colors below to zip them and assign the result to indexes variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexes= zip(<what goes in here>, <what goes in here>)\n",
    "list(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forloop is iterating 4 times in below piece of code. We know samples are labelled as -1 if DBscan could not label them. In each iteration, if the sample label is equal to -1, then it is assigned the color code 'k' which represents black. A new array \"class_member_mask\" is created to store the indexes with True/False values. If the label value matches k(-1 or 0 or 1 or 2 ) then class_member_mask will have True otherwise False. \n",
    "\n",
    "In first iteration, match is an array which has indexes of samples where label is equal to 0 in both class_member_mask and core_samples_mask. nomatch will have indexes of samples where label is equal to 0 in class_member_mask but its not equal to 0 in core_samples_mask. The values in match array are plotted on the map using one a color and values in nomatch are plotted in black color. This repeats for 4 iterations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = 'k'\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    match = Data[class_member_mask & core_samples_mask]\n",
    "    plt.plot(match[:, 0], match[:, 1], 'o', markerfacecolor=col, markeredgecolor='k', markersize=14)\n",
    "\n",
    "    nomatch = Data[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(nomatch[:, 0], nomatch[:, 1], 'o', markerfacecolor=col, markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
