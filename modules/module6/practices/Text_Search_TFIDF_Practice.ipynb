{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Buiding Whoosh Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
    "from whoosh.analysis import StemmingAnalyzer\n",
    "\n",
    "schema = Schema(filename=ID(stored=True),\n",
    "                line_num=ID(stored=True),\n",
    "                content=TEXT(analyzer=StemmingAnalyzer())\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "from whoosh import index\n",
    "\n",
    "# Note, this clears the existing index in the directory\n",
    "ix = index.create_in(\"hp\", schema)\n",
    "\n",
    "# Get a writer form the created index in \n",
    "writer = ix.writer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadFile(writer, fname):\n",
    "    '''\n",
    "    Read file contents, load into database.\n",
    "    '''\n",
    "    line_no = 1\n",
    "    with open(fname, 'r') as infile:\n",
    "        # TODO: create indexes for each line in the input file\n",
    "        for line in infile:\n",
    "            line=line.rstrip('\\n')\n",
    "            line_no+=1\n",
    "            writer.add_document(filename=fname,line_num=str(line_no),content=line)\n",
    "            \n",
    "        print(\"Indexed: \", fname)\n",
    "\n",
    "\n",
    "def processFolder(writer,folder):\n",
    "    print('Processing folder: ',folder)\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        print(\"root = \", root)\n",
    "        # Process Files\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                filename = os.path.join(root, file)\n",
    "                loadFile(writer,filename)\n",
    "            else:\n",
    "                print(\"Unhandled File\")\n",
    "        # Recurse into subfolders\n",
    "        for d in dirs:\n",
    "            print(\"recursing into \",d)\n",
    "            processFolder(writer,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder:  hp\n",
      "root =  hp\n",
      "Indexed:  hp/CHAPTER 1.txt\n",
      "Indexed:  hp/CHAPTER 2.txt\n",
      "Indexed:  hp/CHAPTER 3.txt\n",
      "Indexed:  hp/CHAPTER 4.txt\n",
      "Indexed:  hp/CHAPTER 5.txt\n",
      "Indexed:  hp/CHAPTER 6.txt\n",
      "Indexed:  hp/CHAPTER 7.txt\n",
      "Indexed:  hp/CHAPTER 8.txt\n",
      "Unhandled File\n",
      "Unhandled File\n",
      "Unhandled File\n",
      "Unhandled File\n",
      "Unhandled File\n",
      "recursing into  MAIN.tmp\n",
      "Processing folder:  MAIN.tmp\n",
      "root =  hp/MAIN.tmp\n",
      "Unhandled File\n"
     ]
    }
   ],
   "source": [
    "processFolder(writer,\"hp\")\n",
    "writer.commit() # save changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Executing Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp/CHAPTER 6.txt\n",
      "hp/CHAPTER 2.txt\n",
      "hp/CHAPTER 1.txt\n",
      "hp/CHAPTER 2.txt\n",
      "hp/CHAPTER 3.txt\n",
      "hp/CHAPTER 3.txt\n",
      "hp/CHAPTER 5.txt\n",
      "hp/CHAPTER 6.txt\n",
      "hp/CHAPTER 6.txt\n",
      "hp/CHAPTER 6.txt\n"
     ]
    }
   ],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    "qp=QueryParser(\"content\",schema=ix.schema)\n",
    "q=qp.parse(u\"Harry\")\n",
    "with ix.searcher() as s:\n",
    "    results=s.search(q)\n",
    "    for hit in results:\n",
    "        print(hit[\"filename\"])\n",
    "# Find the indexes of lines where the string 'Harry' is appearing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp/CHAPTER 2.txt\n",
      "hp/CHAPTER 2.txt\n",
      "hp/CHAPTER 2.txt\n",
      "hp/CHAPTER 5.txt\n",
      "hp/CHAPTER 5.txt\n",
      "hp/CHAPTER 5.txt\n",
      "hp/CHAPTER 5.txt\n",
      "hp/CHAPTER 6.txt\n",
      "hp/CHAPTER 6.txt\n",
      "hp/CHAPTER 6.txt\n"
     ]
    }
   ],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    "from whoosh import scoring\n",
    "qp=QueryParser(\"content\",schema=ix.schema)\n",
    "q=qp.parse(u\"Harry\")\n",
    "with ix.searcher(weighting=scoring.TF_IDF()) as s:\n",
    "    results=s.search(q)\n",
    "    for hit in results:\n",
    "        print(hit[\"filename\"])\n",
    "    \n",
    "# Find the indexes of lines where the string 'Harry' using TF_IDF as the scoring mechanism. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-35-666f3f4f06f7>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-666f3f4f06f7>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    for hit in results:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from whoosh.query import *\n",
    "\n",
    "with ix.searcher(weighting=scoring.TF_IDF()) as s:\n",
    "    qp = QueryParser(\"content\", ix.schema)\n",
    "    user_q = qp.parse(u\"Harry\")\n",
    "\n",
    "    # Only show documents in the \"rendering\" chapter\n",
    "    allow_q = Term(\"filename\", \"hp/CHAPTER 6.txt\")\n",
    "    # Don't show any documents where the \"content\" field contains \"hate\"\n",
    "    restrict_q = Term(\"content\",\"hate\")\n",
    "\n",
    "    results = s.search(user_q, mask=restrict_q, filter=allow_q)      #   \n",
    "        for hit in results:\n",
    "            print(hit[\"filename\"], hit[\"content\"])\n",
    "\n",
    "# Use a filter to list the indexes in chapter 6 corresponding to the search string 'Harry' using TF_IDF as the scoring mechanism. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
